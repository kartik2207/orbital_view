{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ySsIOW8OYpPa"
   },
   "source": [
    "## MOUNTING THE DRIVE ON TO GOOGLE COLLAB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6N5MTA8Rde76"
   },
   "source": [
    "Before putting the images I rescaled all the images to 800 X 600. The rescale.py code does this. I have attached the file on the github repo. \n",
    "After rescaling, I annotated the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4316,
     "status": "ok",
     "timestamp": 1586983888620,
     "user": {
      "displayName": "Prashanth Sateesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghq0hqUMmNEUKQxRPvSlHtA0NKiBsKUcHdE8ZmfSQ=s64",
      "userId": "15948660952879560051"
     },
     "user_tz": 240
    },
    "id": "-_2NLdY8Eaky",
    "outputId": "3a8f811e-b2f4-49ce-e139-1ca21cd4e47d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Requirement already satisfied: detecto in /usr/local/lib/python3.6/dist-packages (1.1.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detecto) (3.2.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from detecto) (1.4.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from detecto) (4.1.2.30)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from detecto) (1.0.3)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from detecto) (0.5.0)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from detecto) (0.16.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detecto) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detecto) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detecto) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detecto) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detecto) (1.18.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->detecto) (2018.9)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->detecto) (1.12.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->detecto) (7.0.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->detecto) (1.4.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->detecto) (2.4)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->detecto) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->detecto) (2.4.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->detecto) (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "os.chdir('/content/drive/My Drive/kartik_ov')\n",
    "\n",
    "!pip install detecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BnVfjc3jYykF"
   },
   "source": [
    "## A PRETRAINED MODEL  Faster R-CNN ResNet-50 FPN WHICH WAS TRAINED TO DETECT 80 DIFFERENT OBJECTS WAS USED. AND I USED TRANSFER LEARNING TO RETRAIN IT TO DETECT THE TWITTER FOLLOWING BUTTON. I ACHIEVED THIS BY ANNOTATING THE IMAGE DATA GIVEN TO ME. I ANNOTATED THE 4 IMAGES THAT I GOT FOR TRAINING AND MADE 80 IMAGES OUT OF THEM AND TESTED ON THE 1 IMAGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tprY7rrTE2l1"
   },
   "outputs": [],
   "source": [
    "from detecto import core, utils,visualize\n",
    "from torchvision import transforms\n",
    "augmentations = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x[:,:,:3]),\n",
    "    transforms.ToTensor(),\n",
    "    utils.normalize_transform(),\n",
    "])\n",
    "dataset = core.Dataset('new_images/', transform=augmentations)\n",
    "\n",
    "model = core.Model(['button'])\n",
    "\n",
    "model.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4zLffEovH2Hs"
   },
   "outputs": [],
   "source": [
    "# here we test how the model is working on our test image .\n",
    "image = utils.read_image('test_images/TEST_IMG.png')\n",
    "predictions = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MIEyL_jJJXG5"
   },
   "outputs": [],
   "source": [
    "# we visualize the output we got in the previous cell.\n",
    "visualize.show_labeled_image(image, boxes, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ep_bFMUytQjl"
   },
   "source": [
    "Here we can see that using transfer learning our object recognition model works very well and recogonizes the all the buttons. \n",
    "\n",
    "This is because the initial layers of the model has been already trained using a very large number of objects and right now only the last few layers have been trained using our annotated images to recogonize the twitter following button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eYWwrhrnIYs_"
   },
   "outputs": [],
   "source": [
    "labels, boxes, scores = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 897,
     "status": "ok",
     "timestamp": 1586985243401,
     "user": {
      "displayName": "Prashanth Sateesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghq0hqUMmNEUKQxRPvSlHtA0NKiBsKUcHdE8ZmfSQ=s64",
      "userId": "15948660952879560051"
     },
     "user_tz": 240
    },
    "id": "c9JJbFVgkQjj",
    "outputId": "4e531fed-ec45-47f9-842b-7ae1e036d20e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[281.35883, 633.5201, 302.37955, 758.7993], [108.41306, 634.6256, 129.33368, 758.2214], [168.07912, 633.25665, 189.61053, 758.7443], [569.4175, 631.8878, 590.8806, 757.0614], [431.9754, 632.99725, 452.38263, 759.104], [500.87317, 633.13525, 521.45685, 758.1461], [363.23218, 634.0254, 383.62125, 758.91986], [212.83258, 632.09546, 233.28906, 757.13116], [40.5633, 634.4668, 60.810112, 758.96295]]\n"
     ]
    }
   ],
   "source": [
    "# Here I am putting the coordinates in the required format.\n",
    "import numpy as np\n",
    "boxes=np.array(boxes)\n",
    "def output(boxes):\n",
    "  out=[]\n",
    "  for i in range(len(boxes)):\n",
    "    temp = [boxes[i][1], boxes[i][0],boxes[i][3],boxes[i][2]]\n",
    "  \n",
    "    out.append(temp)\n",
    "  return out\n",
    "out = output(boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 877,
     "status": "ok",
     "timestamp": 1586985278134,
     "user": {
      "displayName": "Prashanth Sateesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghq0hqUMmNEUKQxRPvSlHtA0NKiBsKUcHdE8ZmfSQ=s64",
      "userId": "15948660952879560051"
     },
     "user_tz": 240
    },
    "id": "0cMNqLOmlJLR",
    "outputId": "d0a24d8b-83c0-4c8d-ba2b-a743384f1702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[281.35883, 633.5201, 302.37955, 758.7993]\n",
      "[108.41306, 634.6256, 129.33368, 758.2214]\n",
      "[168.07912, 633.25665, 189.61053, 758.7443]\n",
      "[569.4175, 631.8878, 590.8806, 757.0614]\n",
      "[431.9754, 632.99725, 452.38263, 759.104]\n",
      "[500.87317, 633.13525, 521.45685, 758.1461]\n",
      "[363.23218, 634.0254, 383.62125, 758.91986]\n",
      "[212.83258, 632.09546, 233.28906, 757.13116]\n",
      "[40.5633, 634.4668, 60.810112, 758.96295]\n"
     ]
    }
   ],
   "source": [
    "for i in out:\n",
    "  print(i)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-ENaPl7sfQf"
   },
   "source": [
    "The above shows the ouput of the coordinates of the boxes formed around the following button. The order the numbers is [ymin, xmin, ymax, xmax]. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
